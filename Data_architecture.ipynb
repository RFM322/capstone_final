{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/generalassembly-open-graph.png\" width=\"240\" height=\"240\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data architecture notebook\n",
    "**Author: Rodolfo Flores Mendez**\n",
    "<br> May 2019 | Chicago, IL.\n",
    "\n",
    "### Table of contents\n",
    "- [Overview](#ov)\n",
    "- [Importing libraries](#imp)\n",
    "- [Merging reviews and business data](#me)\n",
    "- [Construction of distance matrix](#dist)\n",
    "- [Construction of category matrix](#cat)\n",
    "- [Script for data architecture as numpy array](#da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview<a id=\"ov\"></a>\n",
    "This notebook presents in detail the script used to create the proposed data architecture for businesses in the \"area of interest\" of \"Las Vegas Strip\", as explained in the Readme. \n",
    "\n",
    "There are (4) key steps to compile the desired data architecture:\n",
    "\n",
    "   - **(1)** Combine the features from multiple dataframes,\n",
    "   - **(2)** Construction of distance matrix to mask businesses given a distance criteria (radius of incluence),\n",
    "   - **(3)** Construction of a cateogry martix to mask businesses given a business category criteria,\n",
    "   - **(4)** Use the distance and category matrix to loop through specific distnace and cateogry bins to build the 4D tensor for the CNN model,\n",
    "    \n",
    "The loop on step (4) to build the data architecture for the CNN model was created using numpy, given that it surpassed the capacity of pandas to manage large sets of multidimensional data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries<a id=\"imp\"></a>\n",
    "In this section we outline the initial code needed to run this workbook. If this code returns an error we recommend the reader to verify that the most up to date version of the libraries mentioned below have been installed in their computers. For a guideline on python installation of modules please refer to the __[official documentation](https://docs.python.org/3/installing/)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "#Time library\n",
    "import time\n",
    "\n",
    "#Setting max rows and columns\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "\n",
    "#Import library for calculating distance between lat and long\n",
    "import utm\n",
    "\n",
    "#Import combination and permutation library\n",
    "from itertools import combinations\n",
    "\n",
    "# Import Gensim for Wrod2Vec similarity\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "#Import Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging reviews and business data <a id=\"imp\"></a>\n",
    "In this section we merge the dataframes that were generated on the preprocessing and data extraction notebooks by business id for the \"area of interest\" of \"Las Vegas Strip\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1SWheh84yJXfytovILXOAQ</th>\n",
       "      <td>33.522143</td>\n",
       "      <td>-112.018481</td>\n",
       "      <td>0</td>\n",
       "      <td>Golf, Active Life</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QXAEGFB4oINsVuTFxEYKFQ</th>\n",
       "      <td>43.605499</td>\n",
       "      <td>-79.652289</td>\n",
       "      <td>1</td>\n",
       "      <td>Specialty Food, Restaurants, Dim Sum, Imported...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>Mississauga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnKjwL_1w79qoiV3IC_xQQ</th>\n",
       "      <td>35.092564</td>\n",
       "      <td>-80.859132</td>\n",
       "      <td>1</td>\n",
       "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170</td>\n",
       "      <td>Charlotte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xvX2CttrVhyG2z1dFg_0xw</th>\n",
       "      <td>33.455613</td>\n",
       "      <td>-112.395596</td>\n",
       "      <td>1</td>\n",
       "      <td>Insurance, Financial Services</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Goodyear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HhyxOkGAM07SRYtlQ4wMFQ</th>\n",
       "      <td>35.190012</td>\n",
       "      <td>-80.887223</td>\n",
       "      <td>1</td>\n",
       "      <td>Plumbing, Shopping, Local Services, Home Servi...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Charlotte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         latitude   longitude  is_open  \\\n",
       "business_id                                              \n",
       "1SWheh84yJXfytovILXOAQ  33.522143 -112.018481        0   \n",
       "QXAEGFB4oINsVuTFxEYKFQ  43.605499  -79.652289        1   \n",
       "gnKjwL_1w79qoiV3IC_xQQ  35.092564  -80.859132        1   \n",
       "xvX2CttrVhyG2z1dFg_0xw  33.455613 -112.395596        1   \n",
       "HhyxOkGAM07SRYtlQ4wMFQ  35.190012  -80.887223        1   \n",
       "\n",
       "                                                               categories  \\\n",
       "business_id                                                                 \n",
       "1SWheh84yJXfytovILXOAQ                                  Golf, Active Life   \n",
       "QXAEGFB4oINsVuTFxEYKFQ  Specialty Food, Restaurants, Dim Sum, Imported...   \n",
       "gnKjwL_1w79qoiV3IC_xQQ                  Sushi Bars, Restaurants, Japanese   \n",
       "xvX2CttrVhyG2z1dFg_0xw                      Insurance, Financial Services   \n",
       "HhyxOkGAM07SRYtlQ4wMFQ  Plumbing, Shopping, Local Services, Home Servi...   \n",
       "\n",
       "                        stars  review_count         city  \n",
       "business_id                                               \n",
       "1SWheh84yJXfytovILXOAQ    3.0             5      Phoenix  \n",
       "QXAEGFB4oINsVuTFxEYKFQ    2.5           128  Mississauga  \n",
       "gnKjwL_1w79qoiV3IC_xQQ    4.0           170    Charlotte  \n",
       "xvX2CttrVhyG2z1dFg_0xw    5.0             3     Goodyear  \n",
       "HhyxOkGAM07SRYtlQ4wMFQ    4.0             4    Charlotte  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data from the CSV folder, business dataframe created on the data extraction process\n",
    "df_business = pd.read_csv('./csv_data/business.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "#Select relevant columns to build the data architecture, these are lat and long for distance metrics (Y dimension),\n",
    "#categories for similarity metrics (X dimension),\n",
    "#and the features we want to model with (such as stars, and review count)\n",
    "df = df_business[['business_id','latitude','longitude','is_open','categories','stars','review_count','city']]\n",
    "df = df.set_index('business_id') #Set the index to be the business id\n",
    "\n",
    "#Visualize the head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will limit the dataframe to the \"Las Vegas Strip\", which is the area of interest for this particular analysis. The code below limits the dataframe for businesses within such geographical area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual representation of the \"area of interest\" of the \"Las Vegas Strip\"**\n",
    "\n",
    "<img src=\"images/las_Vegas.jpg\" width=\"1000\" height=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8527, 7)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define lat and long limits\n",
    "lat_low = 36.092239\n",
    "lat_up = 36.159071\n",
    "\n",
    "long_left = -115.234375\n",
    "long_right = -115.136185\n",
    "\n",
    "#Mask the dataframe for such lat and long area\n",
    "mask = (df['latitude']>=lat_low) & (df['latitude']<=lat_up) & (df['longitude']>=long_left) & (df['longitude']<=long_right)\n",
    "df = df[mask]\n",
    "\n",
    "#Display the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in this particular instance the number of businesses to analyze is 8,527. We will now standarize the data to be able to run it through the data architecture process and the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roflo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\roflo\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8527, 7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standarize data\n",
    "ssFeat = ['stars','review_count']\n",
    "ss = StandardScaler()\n",
    "df_ss = pd.DataFrame(ss.fit_transform(df[ssFeat]),columns = ssFeat)\n",
    "df_ss = pd.concat([df_ss,pd.DataFrame(df.index)],axis=1).set_index('business_id')\n",
    "\n",
    "#Merge the data\n",
    "df = pd.merge(df.drop(columns = ['stars','review_count']),\n",
    "              df_ss,\n",
    "              how='inner',\n",
    "              left_index=True,\n",
    "              right_index=True)\n",
    "\n",
    "#Inspect the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iojTeSaoPuxm4WeCzDUA6w</th>\n",
       "      <td>36.129424</td>\n",
       "      <td>-115.184443</td>\n",
       "      <td>1</td>\n",
       "      <td>Car Rental, Windshield Installation &amp; Repair, ...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>-0.163222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwt9lOpplBAZ7JBrgAqI7g</th>\n",
       "      <td>36.138452</td>\n",
       "      <td>-115.198019</td>\n",
       "      <td>1</td>\n",
       "      <td>Home Services, Real Estate, Apartments</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>-1.658798</td>\n",
       "      <td>-0.290213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R3rss9fkfJxiOK6DueON3w</th>\n",
       "      <td>36.123107</td>\n",
       "      <td>-115.170253</td>\n",
       "      <td>1</td>\n",
       "      <td>Shopping, Women's Clothing, Fashion</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>0.369315</td>\n",
       "      <td>-0.290213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kANF0dbeoW34s2vwh6Umfw</th>\n",
       "      <td>36.125031</td>\n",
       "      <td>-115.225620</td>\n",
       "      <td>0</td>\n",
       "      <td>Fast Food, Food, Restaurants, Ice Cream &amp; Froz...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>-1.658798</td>\n",
       "      <td>-0.214559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gas3YSrKkEcBliUHhnOLTg</th>\n",
       "      <td>36.118157</td>\n",
       "      <td>-115.176430</td>\n",
       "      <td>1</td>\n",
       "      <td>Accessories, Shopping, Fashion, Jewelry, Leath...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>-0.137713</td>\n",
       "      <td>-0.246982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         latitude   longitude  is_open  \\\n",
       "business_id                                              \n",
       "iojTeSaoPuxm4WeCzDUA6w  36.129424 -115.184443        1   \n",
       "Qwt9lOpplBAZ7JBrgAqI7g  36.138452 -115.198019        1   \n",
       "R3rss9fkfJxiOK6DueON3w  36.123107 -115.170253        1   \n",
       "kANF0dbeoW34s2vwh6Umfw  36.125031 -115.225620        0   \n",
       "gas3YSrKkEcBliUHhnOLTg  36.118157 -115.176430        1   \n",
       "\n",
       "                                                               categories  \\\n",
       "business_id                                                                 \n",
       "iojTeSaoPuxm4WeCzDUA6w  Car Rental, Windshield Installation & Repair, ...   \n",
       "Qwt9lOpplBAZ7JBrgAqI7g             Home Services, Real Estate, Apartments   \n",
       "R3rss9fkfJxiOK6DueON3w                Shopping, Women's Clothing, Fashion   \n",
       "kANF0dbeoW34s2vwh6Umfw  Fast Food, Food, Restaurants, Ice Cream & Froz...   \n",
       "gas3YSrKkEcBliUHhnOLTg  Accessories, Shopping, Fashion, Jewelry, Leath...   \n",
       "\n",
       "                             city     stars  review_count  \n",
       "business_id                                                \n",
       "iojTeSaoPuxm4WeCzDUA6w  Las Vegas  0.876344     -0.163222  \n",
       "Qwt9lOpplBAZ7JBrgAqI7g  Las Vegas -1.658798     -0.290213  \n",
       "R3rss9fkfJxiOK6DueON3w  Las Vegas  0.369315     -0.290213  \n",
       "kANF0dbeoW34s2vwh6Umfw  Las Vegas -1.658798     -0.214559  \n",
       "gas3YSrKkEcBliUHhnOLTg  Las Vegas -0.137713     -0.246982  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect the head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will pull in the features from the review dataframe, merge it with this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>rev_stars</th>\n",
       "      <th>positive_comments</th>\n",
       "      <th>negative_comments</th>\n",
       "      <th>age</th>\n",
       "      <th>t_last_c</th>\n",
       "      <th>t_comments</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--9e1ONYQuAa-CB_Rrw7Tw</th>\n",
       "      <td>0.025137</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>4.421910</td>\n",
       "      <td>0.798729</td>\n",
       "      <td>2.149817</td>\n",
       "      <td>-0.652387</td>\n",
       "      <td>2.577041</td>\n",
       "      <td>0.344247</td>\n",
       "      <td>0.590875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--DdmeR16TRb3LsjG0ejrQ</th>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.102740</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-0.279587</td>\n",
       "      <td>-0.295701</td>\n",
       "      <td>-0.035132</td>\n",
       "      <td>1.267161</td>\n",
       "      <td>-0.800340</td>\n",
       "      <td>0.137890</td>\n",
       "      <td>0.506403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--WsruI0IGEoeRmkErU5Gg</th>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>-0.259057</td>\n",
       "      <td>-0.232561</td>\n",
       "      <td>-1.081193</td>\n",
       "      <td>-0.066477</td>\n",
       "      <td>-1.057948</td>\n",
       "      <td>0.229604</td>\n",
       "      <td>0.543175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--z7PM8AGaJP0aBmGMY7RA</th>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.020952</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>-0.226794</td>\n",
       "      <td>-0.274654</td>\n",
       "      <td>-0.008271</td>\n",
       "      <td>-0.523299</td>\n",
       "      <td>0.307380</td>\n",
       "      <td>0.233854</td>\n",
       "      <td>0.476470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0BxAGlIk5DJAGVkpqBXxg</th>\n",
       "      <td>0.014439</td>\n",
       "      <td>0.015878</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.494318</td>\n",
       "      <td>-0.200398</td>\n",
       "      <td>-0.064187</td>\n",
       "      <td>1.630943</td>\n",
       "      <td>-0.502538</td>\n",
       "      <td>1.959645</td>\n",
       "      <td>0.199909</td>\n",
       "      <td>0.574302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cool     funny    useful  rev_stars  \\\n",
       "business_id                                                       \n",
       "--9e1ONYQuAa-CB_Rrw7Tw  0.025137  0.022688  0.025372   0.781457   \n",
       "--DdmeR16TRb3LsjG0ejrQ  0.082353  0.102740  0.071429   0.583333   \n",
       "--WsruI0IGEoeRmkErU5Gg  0.008824  0.002568  0.011905   0.921875   \n",
       "--z7PM8AGaJP0aBmGMY7RA  0.007059  0.008219  0.020952   0.950000   \n",
       "-0BxAGlIk5DJAGVkpqBXxg  0.014439  0.015878  0.017857   0.494318   \n",
       "\n",
       "                        positive_comments  negative_comments       age  \\\n",
       "business_id                                                              \n",
       "--9e1ONYQuAa-CB_Rrw7Tw           4.421910           0.798729  2.149817   \n",
       "--DdmeR16TRb3LsjG0ejrQ          -0.279587          -0.295701 -0.035132   \n",
       "--WsruI0IGEoeRmkErU5Gg          -0.259057          -0.232561 -1.081193   \n",
       "--z7PM8AGaJP0aBmGMY7RA          -0.226794          -0.274654 -0.008271   \n",
       "-0BxAGlIk5DJAGVkpqBXxg          -0.200398          -0.064187  1.630943   \n",
       "\n",
       "                        t_last_c  t_comments  polarity  subjectivity  \n",
       "business_id                                                           \n",
       "--9e1ONYQuAa-CB_Rrw7Tw -0.652387    2.577041  0.344247      0.590875  \n",
       "--DdmeR16TRb3LsjG0ejrQ  1.267161   -0.800340  0.137890      0.506403  \n",
       "--WsruI0IGEoeRmkErU5Gg -0.066477   -1.057948  0.229604      0.543175  \n",
       "--z7PM8AGaJP0aBmGMY7RA -0.523299    0.307380  0.233854      0.476470  \n",
       "-0BxAGlIk5DJAGVkpqBXxg -0.502538    1.959645  0.199909      0.574302  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the df\n",
    "df_reviews = pd.read_csv('./csv_data/reviews_df.csv').set_index('business_id')\n",
    "#Visualize the head\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8527, 11)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect the shape\n",
    "df_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8527, 19)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge both dataframes\n",
    "df= pd.merge(df,\n",
    "             df_reviews,\n",
    "             how='inner',\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "\n",
    "df['is_closed'] = df['is_open'].apply(lambda x: 1 if x==0 else 0)\n",
    "#Check the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>rev_stars</th>\n",
       "      <th>positive_comments</th>\n",
       "      <th>negative_comments</th>\n",
       "      <th>age</th>\n",
       "      <th>t_last_c</th>\n",
       "      <th>t_comments</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>is_closed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iojTeSaoPuxm4WeCzDUA6w</th>\n",
       "      <td>36.129424</td>\n",
       "      <td>-115.184443</td>\n",
       "      <td>1</td>\n",
       "      <td>Car Rental, Windshield Installation &amp; Repair, ...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>-0.163222</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.077601</td>\n",
       "      <td>0.842593</td>\n",
       "      <td>-0.147605</td>\n",
       "      <td>-0.232561</td>\n",
       "      <td>-0.127313</td>\n",
       "      <td>-0.644360</td>\n",
       "      <td>0.259535</td>\n",
       "      <td>0.266891</td>\n",
       "      <td>0.575435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwt9lOpplBAZ7JBrgAqI7g</th>\n",
       "      <td>36.138452</td>\n",
       "      <td>-115.198019</td>\n",
       "      <td>1</td>\n",
       "      <td>Home Services, Real Estate, Apartments</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>-1.658798</td>\n",
       "      <td>-0.290213</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.291319</td>\n",
       "      <td>-0.232561</td>\n",
       "      <td>-1.381839</td>\n",
       "      <td>-0.616790</td>\n",
       "      <td>-1.031203</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>0.446689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R3rss9fkfJxiOK6DueON3w</th>\n",
       "      <td>36.123107</td>\n",
       "      <td>-115.170253</td>\n",
       "      <td>1</td>\n",
       "      <td>Shopping, Women's Clothing, Fashion</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>0.369315</td>\n",
       "      <td>-0.290213</td>\n",
       "      <td>0.042353</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.285453</td>\n",
       "      <td>-0.274654</td>\n",
       "      <td>1.280116</td>\n",
       "      <td>0.673612</td>\n",
       "      <td>0.893604</td>\n",
       "      <td>-0.024604</td>\n",
       "      <td>0.580472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kANF0dbeoW34s2vwh6Umfw</th>\n",
       "      <td>36.125031</td>\n",
       "      <td>-115.225620</td>\n",
       "      <td>0</td>\n",
       "      <td>Fast Food, Food, Restaurants, Ice Cream &amp; Froz...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>-1.658798</td>\n",
       "      <td>-0.214559</td>\n",
       "      <td>0.022460</td>\n",
       "      <td>0.024907</td>\n",
       "      <td>0.026696</td>\n",
       "      <td>0.310606</td>\n",
       "      <td>-0.244392</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.128602</td>\n",
       "      <td>0.248548</td>\n",
       "      <td>0.996227</td>\n",
       "      <td>0.039826</td>\n",
       "      <td>0.530649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gas3YSrKkEcBliUHhnOLTg</th>\n",
       "      <td>36.118157</td>\n",
       "      <td>-115.176430</td>\n",
       "      <td>1</td>\n",
       "      <td>Accessories, Shopping, Fashion, Jewelry, Leath...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>-0.137713</td>\n",
       "      <td>-0.246982</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.238526</td>\n",
       "      <td>-0.274654</td>\n",
       "      <td>-0.839853</td>\n",
       "      <td>-0.532271</td>\n",
       "      <td>-0.531763</td>\n",
       "      <td>0.259513</td>\n",
       "      <td>0.543087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         latitude   longitude  is_open  \\\n",
       "business_id                                              \n",
       "iojTeSaoPuxm4WeCzDUA6w  36.129424 -115.184443        1   \n",
       "Qwt9lOpplBAZ7JBrgAqI7g  36.138452 -115.198019        1   \n",
       "R3rss9fkfJxiOK6DueON3w  36.123107 -115.170253        1   \n",
       "kANF0dbeoW34s2vwh6Umfw  36.125031 -115.225620        0   \n",
       "gas3YSrKkEcBliUHhnOLTg  36.118157 -115.176430        1   \n",
       "\n",
       "                                                               categories  \\\n",
       "business_id                                                                 \n",
       "iojTeSaoPuxm4WeCzDUA6w  Car Rental, Windshield Installation & Repair, ...   \n",
       "Qwt9lOpplBAZ7JBrgAqI7g             Home Services, Real Estate, Apartments   \n",
       "R3rss9fkfJxiOK6DueON3w                Shopping, Women's Clothing, Fashion   \n",
       "kANF0dbeoW34s2vwh6Umfw  Fast Food, Food, Restaurants, Ice Cream & Froz...   \n",
       "gas3YSrKkEcBliUHhnOLTg  Accessories, Shopping, Fashion, Jewelry, Leath...   \n",
       "\n",
       "                             city     stars  review_count      cool     funny  \\\n",
       "business_id                                                                     \n",
       "iojTeSaoPuxm4WeCzDUA6w  Las Vegas  0.876344     -0.163222  0.050980  0.005327   \n",
       "Qwt9lOpplBAZ7JBrgAqI7g  Las Vegas -1.658798     -0.290213  0.007059  0.008219   \n",
       "R3rss9fkfJxiOK6DueON3w  Las Vegas  0.369315     -0.290213  0.042353  0.032877   \n",
       "kANF0dbeoW34s2vwh6Umfw  Las Vegas -1.658798     -0.214559  0.022460  0.024907   \n",
       "gas3YSrKkEcBliUHhnOLTg  Las Vegas -0.137713     -0.246982  0.011765  0.011742   \n",
       "\n",
       "                          useful  rev_stars  positive_comments  \\\n",
       "business_id                                                      \n",
       "iojTeSaoPuxm4WeCzDUA6w  0.077601   0.842593          -0.147605   \n",
       "Qwt9lOpplBAZ7JBrgAqI7g  0.023810   0.300000          -0.291319   \n",
       "R3rss9fkfJxiOK6DueON3w  0.023810   0.700000          -0.285453   \n",
       "kANF0dbeoW34s2vwh6Umfw  0.026696   0.310606          -0.244392   \n",
       "gas3YSrKkEcBliUHhnOLTg  0.015873   0.666667          -0.238526   \n",
       "\n",
       "                        negative_comments       age  t_last_c  t_comments  \\\n",
       "business_id                                                                 \n",
       "iojTeSaoPuxm4WeCzDUA6w          -0.232561 -0.127313 -0.644360    0.259535   \n",
       "Qwt9lOpplBAZ7JBrgAqI7g          -0.232561 -1.381839 -0.616790   -1.031203   \n",
       "R3rss9fkfJxiOK6DueON3w          -0.274654  1.280116  0.673612    0.893604   \n",
       "kANF0dbeoW34s2vwh6Umfw           0.020000  1.128602  0.248548    0.996227   \n",
       "gas3YSrKkEcBliUHhnOLTg          -0.274654 -0.839853 -0.532271   -0.531763   \n",
       "\n",
       "                        polarity  subjectivity  is_closed  \n",
       "business_id                                                \n",
       "iojTeSaoPuxm4WeCzDUA6w  0.266891      0.575435          0  \n",
       "Qwt9lOpplBAZ7JBrgAqI7g -0.004517      0.446689          0  \n",
       "R3rss9fkfJxiOK6DueON3w -0.024604      0.580472          0  \n",
       "kANF0dbeoW34s2vwh6Umfw  0.039826      0.530649          1  \n",
       "gas3YSrKkEcBliUHhnOLTg  0.259513      0.543087          0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save as CSV\n",
    "df.to_csv('./csv_data/df_2d_class.csv')\n",
    "#Inspect the head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of distance matrix<a id=\"dist\"></a>\n",
    "\n",
    "In this section the code to create the distance matrix is detailed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8527, 8527)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create columns that convert the lat and long to UTM in order to compute Euclidean distance\n",
    "values = [utm.from_latlon(x,y)[0] for (x,y) in zip(df['latitude'],df['longitude'])]\n",
    "df['UTM1'] = values\n",
    "values = [utm.from_latlon(x,y)[1] for (x,y) in zip(df['latitude'],df['longitude'])]\n",
    "df['UTM2'] = values\n",
    "\n",
    "#Convert the columns to numpy arrays\n",
    "lats = df['UTM1'].values\n",
    "lons = df['UTM2'].values\n",
    "\n",
    "#Calculate the absolute difference between all the elements of the vector\n",
    "dlats = np.abs(lats[:, None] - lats[None, :])\n",
    "dlongs = np.abs(lons[:, None] - lons[None, :])\n",
    "\n",
    "#Compute Euclidean distance and store on a distance matrix where each row is a vector of the distance of a specific business\n",
    "#to all the other businesses in the dataset\n",
    "distances = np.sqrt((dlats)**2 + (dlongs)**2)\n",
    "\n",
    "#Display the distances shape\n",
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sign matrix to update the distance matrix based on north to south orientation\n",
    "signs = np.sign(np.array(lats[:, None] - lats[None, :]))\n",
    "\n",
    "distances = np.multiply(distances,signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8527, 8527)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check again the shape\n",
    "distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of category  matrix<a id=\"cat\"></a>\n",
    "\n",
    "In this section the code to create the category matrix is detailed.It displays if a given business pertains to a specific category, and then uses this output to create category mask of the same dimensions as the distance martix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expand the Categories column into a dummy field\n",
    "#First obtain a list of all the categories that exist\n",
    "categories = []\n",
    "for x in df['categories']:\n",
    "    if type(x)==float:\n",
    "        continue\n",
    "    else:\n",
    "        categories.extend(x.split(','))\n",
    "\n",
    "#Clean white spaces\n",
    "categories = [x.strip() for x in categories]\n",
    "#Create a list with unique items\n",
    "categories = [str(x) for x in set(categories)]\n",
    "\n",
    "#Create a dataframe\n",
    "frame = []\n",
    "for x in df['categories']:\n",
    "    values=[]\n",
    "    try:\n",
    "        for cat in categories:\n",
    "            if cat in [x.strip() for x in x.split(',')]:\n",
    "                values.append(1)\n",
    "            else:\n",
    "                values.append(0)\n",
    "    except:\n",
    "        for cat in categories:\n",
    "            values.append(0)\n",
    "    \n",
    "    frame.append(values)\n",
    "\n",
    "#Store in a DataFrame\n",
    "df_categories = pd.DataFrame(frame, columns = categories).fillna(0)\n",
    "\n",
    "#Add the business id column\n",
    "df_categories.index=df.index\n",
    "df_categories = df_categories.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id\n",
       "iojTeSaoPuxm4WeCzDUA6w    0.0\n",
       "Qwt9lOpplBAZ7JBrgAqI7g    0.0\n",
       "R3rss9fkfJxiOK6DueON3w    0.0\n",
       "kANF0dbeoW34s2vwh6Umfw    1.0\n",
       "gas3YSrKkEcBliUHhnOLTg    0.0\n",
       "Name: Restaurants, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check a vectors head\n",
    "df_categories['Restaurants'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Language Schools', 'Toy Stores', 'Colonics', 'Advertising',\n",
       "       'Decks & Railing', 'Karate', 'Cultural Center', 'Pool Halls', 'Trusts',\n",
       "       'Video\\/Film Production',\n",
       "       ...\n",
       "       'Gun\\/Rifle Ranges', 'Sporting Goods', 'Henna Artists', 'Tours',\n",
       "       'Photographers', 'Vocational & Technical School', 'Battery Stores',\n",
       "       'other_low', 'other_up', 'top'],\n",
       "      dtype='object', length=953)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following lines of code we will loop through the different distance and category bins to build the data architecure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11109.495594971773"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In order to define the distance bins, we need to look at the distribution of the distance.\n",
    "np.min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11109.495594971773"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11km is the limit for north and south distance. Hennce we will define bins that do not exceed this limits. We also need to define the similarity between the categories, in order to order the categories from middle to outer based on similarity. For this task we will use the Word2Vec library gesmin and train it with the wikipedia archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_split(x):\n",
    "    result = []\n",
    "    for word in x.split(','):\n",
    "        word = word.strip(' ')\n",
    "        result.append(word)\n",
    "    return result\n",
    "\n",
    "df['categories'] = df['categories'].fillna('')\n",
    "corpus = list(df['categories'].apply(lambda x: strip_split(x)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.896151065826416\n"
     ]
    }
   ],
   "source": [
    "# Start timer.\n",
    "t0 = time.time()\n",
    "\n",
    "# Import word vectors into \"model.\"\n",
    "model = Word2Vec(corpus,      # Corpus of data.\n",
    "                 size=100,    # Dimensions\n",
    "                 window=5,    # Context words\n",
    "                 min_count=1, # Ignores words below this threshold.\n",
    "                 sg=0,        # SG = 0 uses CBOW (default).\n",
    "                 workers=4)   # (parallelizes process).\n",
    "\n",
    "# Print results of timer.\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roflo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('American (New)', 0.9935117959976196),\n",
       " ('American (Traditional)', 0.9906449317932129),\n",
       " ('Burgers', 0.9882069826126099),\n",
       " ('Food', 0.9874913692474365),\n",
       " ('Sports Bars', 0.9850655794143677),\n",
       " ('Bars', 0.9816811680793762),\n",
       " ('Breakfast & Brunch', 0.9816216230392456),\n",
       " ('Steakhouses', 0.9791653156280518),\n",
       " ('Italian', 0.9789568185806274),\n",
       " ('Pizza', 0.9783942699432373),\n",
       " ('Sandwiches', 0.9778966903686523),\n",
       " ('Nightlife', 0.9777824878692627),\n",
       " ('Cocktail Bars', 0.9770600199699402),\n",
       " ('Cafes', 0.9761971831321716),\n",
       " ('Wine & Spirits', 0.9735256433486938)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display top 15 similarities\n",
    "similarity = model.most_similar('Restaurants',topn = 15)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['American (New)',\n",
       " 'American (Traditional)',\n",
       " 'Burgers',\n",
       " 'Food',\n",
       " 'Sports Bars',\n",
       " 'Bars',\n",
       " 'Breakfast & Brunch',\n",
       " 'Steakhouses',\n",
       " 'Italian',\n",
       " 'Pizza',\n",
       " 'Sandwiches',\n",
       " 'Nightlife',\n",
       " 'Cocktail Bars',\n",
       " 'Cafes',\n",
       " 'Wine & Spirits']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store top similarities on a list\n",
    "top_c = [x for x,y in similarity]\n",
    "top_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store 0ther categories in a list\n",
    "categories = list(model.wv.vocab.keys())\n",
    "low_c = []\n",
    "for x in categories:\n",
    "    if x in top_c:\n",
    "        pass\n",
    "    else:\n",
    "        low_c.append(x)\n",
    "\n",
    "#Shuffle list\n",
    "random.shuffle(low_c)\n",
    "random.shuffle(low_c)\n",
    "random.shuffle(low_c)\n",
    "\n",
    "#Pop the restaurants category\n",
    "low_c.remove('Restaurants')\n",
    "low_c.remove('')\n",
    "\n",
    "#Split into two groups\n",
    "top_c1 = top_c[:int(len(top_c)/2)]\n",
    "top_c2 = top_c[int(len(top_c)/2):]\n",
    "\n",
    "#Split into two groups\n",
    "low_c1 = low_c[:int(len(low_c)/2)]\n",
    "low_c2 = low_c[int(len(low_c)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_c1 + low_c2 == low_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the category boolean for \"other\", low and up\n",
    "df_categories['other_low'] = df_categories[low_c1].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "df_categories['other_up'] = df_categories[low_c2].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#Create categories for top\n",
    "df_categories['top'] = df_categories[top_c].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#Rewrite the other categories with zero if first category if the business is already captured in the \"top\"\n",
    "df_categories['other_low'] = np.select([(df_categories['top'] == 1) & (df_categories['other_low'] == 1),\n",
    "                                        (df_categories['top'] == 1) & (df_categories['other_low'] == 0),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_low'] == 1),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_low'] == 0)],\n",
    "                                       [0,0,1,0],\n",
    "                                       default = 0)\n",
    "\n",
    "df_categories['other_up'] = np.select([(df_categories['top'] == 1) & (df_categories['other_up'] == 1),\n",
    "                                        (df_categories['top'] == 1) & (df_categories['other_up'] == 0),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_up'] == 1),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_up'] == 0)],\n",
    "                                       [0,0,1,0],\n",
    "                                       default = 0)\n",
    "\n",
    "df_categories['other_up'] = np.select([(df_categories['other_low'] == 1) & (df_categories['other_up'] == 1),\n",
    "                                       (df_categories['other_low'] == 1) & (df_categories['other_up'] == 0),\n",
    "                                       (df_categories['other_low'] == 0) & (df_categories['other_up'] == 1),\n",
    "                                       (df_categories['other_low'] == 0) & (df_categories['other_up'] == 0)],\n",
    "                                      [0,0,1,0],\n",
    "                                      default = 0)\n",
    "\n",
    "#Convert everything to float\n",
    "df_categories = df_categories.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['other_low',\n",
       " 'American (New)',\n",
       " 'American (Traditional)',\n",
       " 'Burgers',\n",
       " 'Food',\n",
       " 'Sports Bars',\n",
       " 'Bars',\n",
       " 'Breakfast & Brunch',\n",
       " 'Restaurants',\n",
       " 'Steakhouses',\n",
       " 'Italian',\n",
       " 'Pizza',\n",
       " 'Sandwiches',\n",
       " 'Nightlife',\n",
       " 'Cocktail Bars',\n",
       " 'Cafes',\n",
       " 'Wine & Spirits',\n",
       " 'other_up']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the list of bins to include in the model\n",
    "['other_low'] + top_c1 + ['Restaurants'] + top_c2 +['other_up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>other_low</th>\n",
       "      <th>other_up</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HvJwmfRW2JYwalB5DCeH4A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FxhPnGuHqLHkBX9p1jm06Q</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rXFMVZtJzuCG6bBlmsRjuQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLC594vCsmpdDkT7iu2MeQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YA9nDSe7_9j9HrQ-qXrjAA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F6ScBoyzVPhuvyJUUdUZ9Q</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nySa840axVEJUcAjg_sTCQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3GfdCuI0YCc5U3rLLLPHUw</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vDIZQffxHxbli2u4DsZ4uQ</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2ZWxWi_Ci8nyRiXA0WS4Q</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VR_sPtvU1klpbsneylTTig</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RRpHuoXpxcuLk4LdB_YrOg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o0fP5Vb5k_55bS1Yx_3S1g</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P8uECqGqXWTwEndkh-6bQw</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KxL0-DkQW18UBHVYLeHqLg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eJFa1FVr6Qs2g2SPKHPjgA</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VcLDJACmIEBHMME3b2gnMg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VrORMw6HQhwuBPciGpb6yw</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SoPVLaoQlHuoZlt4fQBXTw</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1f_VAX1KIK8-JoVhjbYOw</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        top  other_low  other_up\n",
       "business_id                                     \n",
       "HvJwmfRW2JYwalB5DCeH4A  0.0        1.0       0.0\n",
       "FxhPnGuHqLHkBX9p1jm06Q  1.0        0.0       0.0\n",
       "rXFMVZtJzuCG6bBlmsRjuQ  0.0        1.0       0.0\n",
       "TLC594vCsmpdDkT7iu2MeQ  0.0        1.0       0.0\n",
       "YA9nDSe7_9j9HrQ-qXrjAA  0.0        0.0       1.0\n",
       "F6ScBoyzVPhuvyJUUdUZ9Q  0.0        1.0       0.0\n",
       "nySa840axVEJUcAjg_sTCQ  0.0        1.0       0.0\n",
       "3GfdCuI0YCc5U3rLLLPHUw  1.0        0.0       0.0\n",
       "vDIZQffxHxbli2u4DsZ4uQ  1.0        0.0       0.0\n",
       "F2ZWxWi_Ci8nyRiXA0WS4Q  1.0        0.0       0.0\n",
       "VR_sPtvU1klpbsneylTTig  1.0        0.0       0.0\n",
       "RRpHuoXpxcuLk4LdB_YrOg  0.0        1.0       0.0\n",
       "o0fP5Vb5k_55bS1Yx_3S1g  0.0        1.0       0.0\n",
       "P8uECqGqXWTwEndkh-6bQw  1.0        0.0       0.0\n",
       "KxL0-DkQW18UBHVYLeHqLg  1.0        0.0       0.0\n",
       "eJFa1FVr6Qs2g2SPKHPjgA  1.0        0.0       0.0\n",
       "VcLDJACmIEBHMME3b2gnMg  0.0        1.0       0.0\n",
       "VrORMw6HQhwuBPciGpb6yw  0.0        1.0       0.0\n",
       "SoPVLaoQlHuoZlt4fQBXTw  1.0        0.0       0.0\n",
       "c1f_VAX1KIK8-JoVhjbYOw  0.0        0.0       1.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize the other low and other up vectors (there should be no overlap)\n",
    "df_categories[['top','other_low','other_up']].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7611\n",
       "1.0     916\n",
       "Name: other_up, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories['other_up'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    4774\n",
       "0.0    3753\n",
       "Name: other_low, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories['other_low'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script of the data architecture<a id=\"da\"></a>\n",
    "\n",
    "In this section the code to create the data architecture for the CNN is detailed. The steps it follows are:\n",
    "\n",
    "   - **(1) Define bins:** Define category and distance bins as lists to compose the \"x\" and \"y\" axis of each businesses grid. \n",
    "   - **(2) Select features:** Select the features to include in the \"feature array\". \n",
    "   - **(3) Loop through bins to create a numpy array witht he desired architecture** Loops through the criteria defined on steps (1) and (2) and stores a numpy array with the desired 4D architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roflo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "#Define categories to loop on\n",
    "categories = ['other_low'] + top_c1 + ['Restaurants'] + top_c2 + ['other_up']\n",
    "\n",
    "#Define distances to loop on\n",
    "dist_lst = [\n",
    "    [5000,int(np.max(distances))],\n",
    "    [2500,5000],\n",
    "    [1000,2500],\n",
    "    [500,1000],\n",
    "    [250,500],\n",
    "    [100,250],\n",
    "    [50,100],\n",
    "    [0,50],\n",
    "    [-50,0],\n",
    "    [-100,-50],\n",
    "    [-250,-100],\n",
    "    [-500,-250],\n",
    "    [-1000,-500],\n",
    "    [-2500,-1000],\n",
    "    [-5000,-2500],\n",
    "    [int(np.min(distances)),-5000]\n",
    "]\n",
    "\n",
    "#Define features to loop on\n",
    "features = ['stars','rev_stars','cool','funny','useful','positive_comments','negative_comments','age','polarity','subjectivity'] \n",
    "\n",
    "#Define empty arrays\n",
    "All = np.empty((distances.shape[0],0)) #For inner loop on cat and distance\n",
    "\n",
    "#Extract category boolean vector for each category\n",
    "for cat in categories:\n",
    "    category = np.array(df_categories[cat]) #Create numpy array\n",
    "    category = np.tile(category,(distances.shape[0],1)) #Reshape as distances martix\n",
    "    \n",
    "    #Loop through distance bins to create distance and category mask\n",
    "    for dist in dist_lst:\n",
    "        distance_mask = (distances >= dist[0]) & (distances < dist[1])\n",
    "        mask = np.multiply(distance_mask,category)\n",
    "        \n",
    "        #Loop through features to apply such calculation to the mask\n",
    "        for feature in features:\n",
    "            stars = np.tile(df[feature].values,(distances.shape[0],1))\n",
    "            values = np.multiply(mask,stars)\n",
    "            values[values==0]=np.nan\n",
    "            means = np.nan_to_num(np.nanmean(values[:,:],axis=1))\n",
    "            means = np.where(means!=0,means - df[feature].values,0)\n",
    "            means = means.reshape(means.shape[0],1)\n",
    "            \n",
    "            #Assign to values unique array\n",
    "            All = np.concatenate((All, means),axis=1)\n",
    "  \n",
    "#Reshape all the array into the right format for the CNN\n",
    "All = All.reshape((distances.shape[0],\n",
    "                   len(categories),\n",
    "                   len(dist_lst),\n",
    "                   len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8527, 18, 16, 10)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets inspect the shape\n",
    "All.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataset\n",
    "np.save('./numpy_arrays/cnn_dataset_rest',All)\n",
    "\n",
    "#Save the target variable\n",
    "np.save('./numpy_arrays/target_rest',df['is_closed'].values)\n",
    "\n",
    "#Save the observation's id\n",
    "np.save('./numpy_arrays/ids_rest',np.array(df.index))\n",
    "\n",
    "#Save the Main category id (Restaurants) - used for masking this specific business category in the modelling process\n",
    "np.save('./numpy_arrays/rest_category',df_categories['Restaurants'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The script above loops over restaurants as the main category of interest**\n",
    "The scripts that follow loop through other categories of interest such as \"Food\", \"Bars, and \"Cafes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roflo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "C:\\Users\\roflo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:107: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "#Create category similarity\n",
    "similarity = model.most_similar('Food',topn = 15)\n",
    "top_c = [x for x,y in similarity]\n",
    "#Store 0ther categories in a list\n",
    "categories = list(model.wv.vocab.keys())\n",
    "low_c = []\n",
    "for x in categories:\n",
    "    if x in top_c:\n",
    "        pass\n",
    "    else:\n",
    "        low_c.append(x)\n",
    "\n",
    "#Shuffle list\n",
    "random.shuffle(low_c)\n",
    "random.shuffle(low_c)\n",
    "random.shuffle(low_c)\n",
    "\n",
    "#Pop the restaurants category\n",
    "low_c.remove('Food')\n",
    "low_c.remove('')\n",
    "\n",
    "#Split into two groups\n",
    "top_c1 = top_c[:int(len(top_c)/2)]\n",
    "top_c2 = top_c[int(len(top_c)/2):]\n",
    "\n",
    "#Split into two groups\n",
    "low_c1 = low_c[:int(len(low_c)/2)]\n",
    "low_c2 = low_c[int(len(low_c)/2):]\n",
    "\n",
    "\n",
    "#Create the category boolean for \"other\", low and up\n",
    "df_categories['other_low'] = df_categories[low_c1].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "df_categories['other_up'] = df_categories[low_c2].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#Create categories for top\n",
    "df_categories['top'] = df_categories[top_c].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#Rewrite the other categories with zero if first category if the business is already captured in the \"top\"\n",
    "df_categories['other_low'] = np.select([(df_categories['top'] == 1) & (df_categories['other_low'] == 1),\n",
    "                                        (df_categories['top'] == 1) & (df_categories['other_low'] == 0),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_low'] == 1),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_low'] == 0)],\n",
    "                                       [0,0,1,0],\n",
    "                                       default = 0)\n",
    "\n",
    "df_categories['other_up'] = np.select([(df_categories['top'] == 1) & (df_categories['other_up'] == 1),\n",
    "                                        (df_categories['top'] == 1) & (df_categories['other_up'] == 0),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_up'] == 1),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_up'] == 0)],\n",
    "                                       [0,0,1,0],\n",
    "                                       default = 0)\n",
    "\n",
    "df_categories['other_up'] = np.select([(df_categories['other_low'] == 1) & (df_categories['other_up'] == 1),\n",
    "                                       (df_categories['other_low'] == 1) & (df_categories['other_up'] == 0),\n",
    "                                       (df_categories['other_low'] == 0) & (df_categories['other_up'] == 1),\n",
    "                                       (df_categories['other_low'] == 0) & (df_categories['other_up'] == 0)],\n",
    "                                      [0,0,1,0],\n",
    "                                      default = 0)\n",
    "\n",
    "#Convert everything to float\n",
    "df_categories = df_categories.astype(float)\n",
    "\n",
    "#Define categories to loop on\n",
    "categories = ['other_low'] + top_c1 + ['Food'] + top_c2 + ['other_up']\n",
    "\n",
    "#Define distances to loop on\n",
    "dist_lst = [\n",
    "    [5000,int(np.max(distances))],\n",
    "    [2500,5000],\n",
    "    [1000,2500],\n",
    "    [500,1000],\n",
    "    [250,500],\n",
    "    [100,250],\n",
    "    [50,100],\n",
    "    [0,50],\n",
    "    [-50,0],\n",
    "    [-100,-50],\n",
    "    [-250,-100],\n",
    "    [-500,-250],\n",
    "    [-1000,-500],\n",
    "    [-2500,-1000],\n",
    "    [-5000,-2500],\n",
    "    [int(np.min(distances)),-5000]\n",
    "]\n",
    "\n",
    "#Define features to loop on\n",
    "features = ['stars','rev_stars','cool','funny','useful','positive_comments','negative_comments','age','polarity','subjectivity']\n",
    "\n",
    "#Define empty arrays\n",
    "All = np.empty((distances.shape[0],0)) #For inner loop on cat and distance\n",
    "\n",
    "#Extract category boolean vector for each category\n",
    "for cat in categories:\n",
    "    category = np.array(df_categories[cat]) #Create numpy array\n",
    "    category = np.tile(category,(distances.shape[0],1)) #Reshape as distances martix\n",
    "    \n",
    "    #Loop through distance bins to create distance and category mask\n",
    "    for dist in dist_lst:\n",
    "        distance_mask = (distances >= dist[0]) & (distances < dist[1])\n",
    "        mask = np.multiply(distance_mask,category)\n",
    "        \n",
    "        #Loop through features to apply such calculation to the mask\n",
    "        for feature in features:\n",
    "            stars = np.tile(df[feature].values,(distances.shape[0],1))\n",
    "            values = np.multiply(mask,stars)\n",
    "            values[values==0]=np.nan\n",
    "            means = np.nan_to_num(np.nanmean(values[:,:],axis=1))\n",
    "            means = np.where(means!=0,means - df[feature].values,0)\n",
    "            means = means.reshape(means.shape[0],1)\n",
    "            \n",
    "            #Assign to values unique array\n",
    "            All = np.concatenate((All, means),axis=1)\n",
    "  \n",
    "#Reshape all the array into the right format for the CNN\n",
    "All = All.reshape((distances.shape[0],\n",
    "                   len(categories),\n",
    "                   len(dist_lst),\n",
    "                   len(features)))\n",
    "\n",
    "#Save the dataset\n",
    "np.save('./numpy_arrays/cnn_dataset_food',All)\n",
    "\n",
    "#Save the target variable\n",
    "np.save('./numpy_arrays/target_food',df['is_closed'].values)\n",
    "\n",
    "#Save the observation's id\n",
    "np.save('./numpy_arrays/ids_food',np.array(df.index))\n",
    "\n",
    "#Save the Main category id (Restaurants)\n",
    "np.save('./numpy_arrays/food_category',df_categories['Food'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Bars ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roflo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "C:\\Users\\roflo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:106: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "#Create category similarity\n",
    "similarity = model.most_similar('Bars',topn = 15)\n",
    "top_c = [x for x,y in similarity]\n",
    "#Store 0ther categories in a list\n",
    "categories = list(model.wv.vocab.keys())\n",
    "low_c = []\n",
    "for x in categories:\n",
    "    if x in top_c:\n",
    "        pass\n",
    "    else:\n",
    "        low_c.append(x)\n",
    "\n",
    "#Shuffle list\n",
    "random.shuffle(low_c)\n",
    "random.shuffle(low_c)\n",
    "random.shuffle(low_c)\n",
    "\n",
    "#Pop the restaurants category\n",
    "low_c.remove('Bars')\n",
    "low_c.remove('')\n",
    "\n",
    "#Split into two groups\n",
    "top_c1 = top_c[:int(len(top_c)/2)]\n",
    "top_c2 = top_c[int(len(top_c)/2):]\n",
    "\n",
    "#Split into two groups\n",
    "low_c1 = low_c[:int(len(low_c)/2)]\n",
    "low_c2 = low_c[int(len(low_c)/2):]\n",
    "\n",
    "#Create the category boolean for \"other\", low and up\n",
    "df_categories['other_low'] = df_categories[low_c1].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "df_categories['other_up'] = df_categories[low_c2].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#Create categories for top\n",
    "df_categories['top'] = df_categories[top_c].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#Rewrite the other categories with zero if first category if the business is already captured in the \"top\"\n",
    "df_categories['other_low'] = np.select([(df_categories['top'] == 1) & (df_categories['other_low'] == 1),\n",
    "                                        (df_categories['top'] == 1) & (df_categories['other_low'] == 0),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_low'] == 1),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_low'] == 0)],\n",
    "                                       [0,0,1,0],\n",
    "                                       default = 0)\n",
    "\n",
    "df_categories['other_up'] = np.select([(df_categories['top'] == 1) & (df_categories['other_up'] == 1),\n",
    "                                        (df_categories['top'] == 1) & (df_categories['other_up'] == 0),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_up'] == 1),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_up'] == 0)],\n",
    "                                       [0,0,1,0],\n",
    "                                       default = 0)\n",
    "\n",
    "df_categories['other_up'] = np.select([(df_categories['other_low'] == 1) & (df_categories['other_up'] == 1),\n",
    "                                       (df_categories['other_low'] == 1) & (df_categories['other_up'] == 0),\n",
    "                                       (df_categories['other_low'] == 0) & (df_categories['other_up'] == 1),\n",
    "                                       (df_categories['other_low'] == 0) & (df_categories['other_up'] == 0)],\n",
    "                                      [0,0,1,0],\n",
    "                                      default = 0)\n",
    "\n",
    "#Convert everything to float\n",
    "df_categories = df_categories.astype(float)\n",
    "\n",
    "#Define categories to loop on\n",
    "categories = ['other_low'] + top_c1 + ['Bars'] + top_c2 + ['other_up']\n",
    "\n",
    "#Define distances to loop on\n",
    "dist_lst = [\n",
    "    [5000,int(np.max(distances))],\n",
    "    [2500,5000],\n",
    "    [1000,2500],\n",
    "    [500,1000],\n",
    "    [250,500],\n",
    "    [100,250],\n",
    "    [50,100],\n",
    "    [0,50],\n",
    "    [-50,0],\n",
    "    [-100,-50],\n",
    "    [-250,-100],\n",
    "    [-500,-250],\n",
    "    [-1000,-500],\n",
    "    [-2500,-1000],\n",
    "    [-5000,-2500],\n",
    "    [int(np.min(distances)),-5000]\n",
    "]\n",
    "\n",
    "#Define features to loop on\n",
    "features = ['stars','rev_stars','cool','funny','useful','positive_comments','negative_comments','age','polarity','subjectivity'] \n",
    "\n",
    "#Define empty arrays\n",
    "All = np.empty((distances.shape[0],0)) #For inner loop on cat and distance\n",
    "\n",
    "#Extract category boolean vector for each category\n",
    "for cat in categories:\n",
    "    category = np.array(df_categories[cat]) #Create numpy array\n",
    "    category = np.tile(category,(distances.shape[0],1)) #Reshape as distances martix\n",
    "    \n",
    "    #Loop through distance bins to create distance and category mask\n",
    "    for dist in dist_lst:\n",
    "        distance_mask = (distances >= dist[0]) & (distances < dist[1])\n",
    "        mask = np.multiply(distance_mask,category)\n",
    "        \n",
    "        #Loop through features to apply such calculation to the mask\n",
    "        for feature in features:\n",
    "            stars = np.tile(df[feature].values,(distances.shape[0],1))\n",
    "            values = np.multiply(mask,stars)\n",
    "            values[values==0]=np.nan\n",
    "            means = np.nan_to_num(np.nanmean(values[:,:],axis=1))\n",
    "            means = np.where(means!=0,means - df[feature].values,0)\n",
    "            means = means.reshape(means.shape[0],1)\n",
    "            \n",
    "            #Assign to values unique array\n",
    "            All = np.concatenate((All, means),axis=1)\n",
    "  \n",
    "#Reshape all the array into the right format for the CNN\n",
    "All = All.reshape((distances.shape[0],\n",
    "                   len(categories),\n",
    "                   len(dist_lst),\n",
    "                   len(features)))\n",
    "\n",
    "#Save the dataset\n",
    "np.save('./numpy_arrays/cnn_dataset_bars',All)\n",
    "\n",
    "#Save the target variable\n",
    "np.save('./numpy_arrays/target_bars',df['is_closed'].values)\n",
    "\n",
    "#Save the observation's id\n",
    "np.save('./numpy_arrays/ids_bars',np.array(df.index))\n",
    "\n",
    "#Save the Main category id (Restaurants)\n",
    "np.save('./numpy_arrays/bars_category',df_categories['Bars'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Cafes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roflo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "C:\\Users\\roflo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:106: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "#Create category similarity\n",
    "similarity = model.most_similar('Cafes',topn = 15)\n",
    "top_c = [x for x,y in similarity]\n",
    "#Store 0ther categories in a list\n",
    "categories = list(model.wv.vocab.keys())\n",
    "low_c = []\n",
    "for x in categories:\n",
    "    if x in top_c:\n",
    "        pass\n",
    "    else:\n",
    "        low_c.append(x)\n",
    "\n",
    "#Shuffle list\n",
    "random.shuffle(low_c)\n",
    "random.shuffle(low_c)\n",
    "random.shuffle(low_c)\n",
    "\n",
    "#Pop the restaurants category\n",
    "low_c.remove('Cafes')\n",
    "low_c.remove('')\n",
    "\n",
    "#Split into two groups\n",
    "top_c1 = top_c[:int(len(top_c)/2)]\n",
    "top_c2 = top_c[int(len(top_c)/2):]\n",
    "\n",
    "#Split into two groups\n",
    "low_c1 = low_c[:int(len(low_c)/2)]\n",
    "low_c2 = low_c[int(len(low_c)/2):]\n",
    "\n",
    "#Create the category boolean for \"other\", low and up\n",
    "df_categories['other_low'] = df_categories[low_c1].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "df_categories['other_up'] = df_categories[low_c2].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#Create categories for top\n",
    "df_categories['top'] = df_categories[top_c].fillna(0).sum(axis=1).apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#Rewrite the other categories with zero if first category if the business is already captured in the \"top\"\n",
    "df_categories['other_low'] = np.select([(df_categories['top'] == 1) & (df_categories['other_low'] == 1),\n",
    "                                        (df_categories['top'] == 1) & (df_categories['other_low'] == 0),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_low'] == 1),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_low'] == 0)],\n",
    "                                       [0,0,1,0],\n",
    "                                       default = 0)\n",
    "\n",
    "df_categories['other_up'] = np.select([(df_categories['top'] == 1) & (df_categories['other_up'] == 1),\n",
    "                                        (df_categories['top'] == 1) & (df_categories['other_up'] == 0),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_up'] == 1),\n",
    "                                        (df_categories['top'] == 0) & (df_categories['other_up'] == 0)],\n",
    "                                       [0,0,1,0],\n",
    "                                       default = 0)\n",
    "\n",
    "df_categories['other_up'] = np.select([(df_categories['other_low'] == 1) & (df_categories['other_up'] == 1),\n",
    "                                       (df_categories['other_low'] == 1) & (df_categories['other_up'] == 0),\n",
    "                                       (df_categories['other_low'] == 0) & (df_categories['other_up'] == 1),\n",
    "                                       (df_categories['other_low'] == 0) & (df_categories['other_up'] == 0)],\n",
    "                                      [0,0,1,0],\n",
    "                                      default = 0)\n",
    "\n",
    "#Convert everything to float\n",
    "df_categories = df_categories.astype(float)\n",
    "\n",
    "#Define categories to loop on\n",
    "categories = ['other_low'] + top_c1 + ['Shopping'] + top_c2 + ['other_up']\n",
    "\n",
    "#Define distances to loop on\n",
    "dist_lst = [\n",
    "    [5000,int(np.max(distances))],\n",
    "    [2500,5000],\n",
    "    [1000,2500],\n",
    "    [500,1000],\n",
    "    [250,500],\n",
    "    [100,250],\n",
    "    [50,100],\n",
    "    [0,50],\n",
    "    [-50,0],\n",
    "    [-100,-50],\n",
    "    [-250,-100],\n",
    "    [-500,-250],\n",
    "    [-1000,-500],\n",
    "    [-2500,-1000],\n",
    "    [-5000,-2500],\n",
    "    [int(np.min(distances)),-5000]\n",
    "]\n",
    "\n",
    "#Define features to loop on\n",
    "features = ['stars','rev_stars','cool','funny','useful','positive_comments','negative_comments','age','polarity','subjectivity'] \n",
    "\n",
    "#Define empty arrays\n",
    "All = np.empty((distances.shape[0],0)) #For inner loop on cat and distance\n",
    "\n",
    "#Extract category boolean vector for each category\n",
    "for cat in categories:\n",
    "    category = np.array(df_categories[cat]) #Create numpy array\n",
    "    category = np.tile(category,(distances.shape[0],1)) #Reshape as distances martix\n",
    "    \n",
    "    #Loop through distance bins to create distance and category mask\n",
    "    for dist in dist_lst:\n",
    "        distance_mask = (distances >= dist[0]) & (distances < dist[1])\n",
    "        mask = np.multiply(distance_mask,category)\n",
    "        \n",
    "        #Loop through features to apply such calculation to the mask\n",
    "        for feature in features:\n",
    "            stars = np.tile(df[feature].values,(distances.shape[0],1))\n",
    "            values = np.multiply(mask,stars)\n",
    "            values[values==0]=np.nan\n",
    "            means = np.nan_to_num(np.nanmean(values[:,:],axis=1))\n",
    "            means = np.where(means!=0,means - df[feature].values,0)\n",
    "            means = means.reshape(means.shape[0],1)\n",
    "            \n",
    "            #Assign to values unique array\n",
    "            All = np.concatenate((All, means),axis=1)\n",
    "  \n",
    "#Reshape all the array into the right format for the CNN\n",
    "All = All.reshape((distances.shape[0],\n",
    "                   len(categories),\n",
    "                   len(dist_lst),\n",
    "                   len(features)))\n",
    "\n",
    "#Save the dataset\n",
    "np.save('./numpy_arrays/cnn_dataset_cafes',All)\n",
    "\n",
    "#Save the target variable\n",
    "np.save('./numpy_arrays/target_cafes',df['is_closed'].values)\n",
    "\n",
    "#Save the observation's id\n",
    "np.save('./numpy_arrays/ids_cafes',np.array(df.index))\n",
    "\n",
    "#Save the Main category id (Restaurants)\n",
    "np.save('./numpy_arrays/cafes_category',df_categories['Cafes'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
